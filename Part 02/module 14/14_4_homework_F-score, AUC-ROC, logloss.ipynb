{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0RpWMuyhXNc"
      },
      "source": [
        "# Курс Data Science\n",
        "## 14.4. Домашняя работа\n",
        "\n",
        "Продолжим работу с метриками классификации. В предыдущем задании мы разобрали матрицу ошибок и две основные метрики, которые используются при бинарной классификации.\n",
        "\n",
        "Сейчас рассмотрим F-меру - совокупную метрику по precision и recall - и более сложную AUC-ROC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "data = pd.read_csv('Titanic_train.csv')\n",
        "\n",
        "# Вычислим медианный возраст по полу\n",
        "median_age_male = data['Age'][data['Sex']=='male'].median()\n",
        "median_age_female = data['Age'][data['Sex']=='female'].median()\n",
        "\n",
        "# Заполним пустые значения медианами исходя из пола\n",
        "data['Age'][data['Sex'] == 'male'] = data['Age'].fillna(median_age_male)\n",
        "data['Age'][data['Sex'] == 'female'] = data['Age'].fillna(median_age_female)\n",
        "\n",
        "# Заполним пустые значения в колонках Cabin и Embarked\n",
        "data['Cabin'] = data['Cabin'].fillna('U')\n",
        "data['Embarked'] = data['Embarked'].fillna('U')\n",
        "\n",
        "data = data.replace(['male','female'],[0,1])\n",
        "data = data.replace(['U','S','C','Q'],[0,1,2,3])\n",
        "data.drop(\n",
        "    columns=['PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
        "    axis=1,  # 1 - колонки, 0 - строки\n",
        "    inplace=True  # Применить изменения прямо в датафрейме\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "data_target = data['Survived']\n",
        "data_features = data.drop(\n",
        "    columns=['Survived'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data_features, \n",
        "    data_target, \n",
        "    random_state=17, \n",
        "    test_size=0.25\n",
        ")\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model = knn.fit(X_train, y_train)\n",
        "knn_predict = knn.predict(X_test)\n",
        "\n",
        "recall = recall_score(y_test, knn_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "desLnfjBhXNe"
      },
      "source": [
        "### 2.1\n",
        "Из задания к предыдущему уроку выберите классификатор, который давал наименьшее значение recall, вычислите для него precision, применив precision_score, и самостоятельно посчитайте F1-меру (расчеты должны присутствовать). Затем проверьте ответ, используя встроенную функцию.\n",
        "\n",
        "Сравните полученную f1-меру со значением среднего арифметического полноты и точности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "PqBv_cQmhXNf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, f1_score\n",
        "precision = precision_score(y_test, knn_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "7inF9IHdhXNl"
      },
      "outputs": [],
      "source": [
        "F1 = 2 * (precision * recall)/(precision + recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5696202531645569\n",
            "0.5696202531645569\n"
          ]
        }
      ],
      "source": [
        "print(F1)\n",
        "print(f1_score(y_test, knn_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx1hiPXxhXNp"
      },
      "source": [
        "В библиотеке sklearn есть удобная функция classification_report, возвращающая precision, recall, F-меру и количество экземпляров каждого класса в удобном для чтения формате. Также существует функция precision_recall_fscore_support, возвращающая те же самые метрики, но в форме массива.\n",
        "\n",
        "### 2.2\n",
        "Для каждого классификатора из предыдущего урока рассчитайте и выведите следующие импортированные метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "vhcIcGX5hXNq"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "zUPZhuTGhXNt"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "gnb = GaussianNB()\n",
        "dtc = DecisionTreeClassifier()\n",
        "lr = LogisticRegression()\n",
        "\n",
        "knn_model = knn.fit(X_train, y_train)\n",
        "knn_predict = knn.predict(X_test)\n",
        "gnb_model = gnb.fit(X_train, y_train)\n",
        "gnb_predict = gnb.predict(X_test)\n",
        "dtc_model = dtc.fit(X_train, y_train)\n",
        "dtc_predict = dtc.predict(X_test)\n",
        "lr_model = lr.fit(X_train, y_train)\n",
        "lr_predict = lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classificator_info(classificator, y_test, predicts):\n",
        "    print(type(classificator))\n",
        "    print('----------------')\n",
        "    print(precision_recall_fscore_support(y_test, predicts))\n",
        "    print(classification_report(y_test, predicts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
            "----------------\n",
            "(array([0.70063694, 0.68181818]), array([0.83969466, 0.48913043]), array([0.76388889, 0.56962025]), array([131,  92], dtype=int64))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.84      0.76       131\n",
            "           1       0.68      0.49      0.57        92\n",
            "\n",
            "    accuracy                           0.70       223\n",
            "   macro avg       0.69      0.66      0.67       223\n",
            "weighted avg       0.69      0.70      0.68       223\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classificator_info(knn, y_test, knn_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.naive_bayes.GaussianNB'>\n",
            "----------------\n",
            "(array([0.80434783, 0.76470588]), array([0.84732824, 0.70652174]), array([0.82527881, 0.73446328]), array([131,  92], dtype=int64))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.83       131\n",
            "           1       0.76      0.71      0.73        92\n",
            "\n",
            "    accuracy                           0.79       223\n",
            "   macro avg       0.78      0.78      0.78       223\n",
            "weighted avg       0.79      0.79      0.79       223\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classificator_info(gnb, y_test, gnb_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
            "----------------\n",
            "(array([0.80714286, 0.78313253]), array([0.86259542, 0.70652174]), array([0.83394834, 0.74285714]), array([131,  92], dtype=int64))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83       131\n",
            "           1       0.78      0.71      0.74        92\n",
            "\n",
            "    accuracy                           0.80       223\n",
            "   macro avg       0.80      0.78      0.79       223\n",
            "weighted avg       0.80      0.80      0.80       223\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classificator_info(dtc, y_test, dtc_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
            "----------------\n",
            "(array([0.8028169 , 0.79012346]), array([0.87022901, 0.69565217]), array([0.83516484, 0.73988439]), array([131,  92], dtype=int64))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.84       131\n",
            "           1       0.79      0.70      0.74        92\n",
            "\n",
            "    accuracy                           0.80       223\n",
            "   macro avg       0.80      0.78      0.79       223\n",
            "weighted avg       0.80      0.80      0.80       223\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classificator_info(lr, y_test, lr_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-j5LLf3hXNx"
      },
      "source": [
        "### 2.3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAisAae0hXNx"
      },
      "source": [
        "Вернемся к классификатору LogisticRegression, который мы обучали в предыдущем задании. Там мы не затрагивали настройку гиперпараметров: сделать это можно с помощью LogisticRegressionCV - перебора параметров по сетке с последующей кросс-валидацией (по сути это аналог GridSearchCV, но со своими параметрами внутри, применимыми только к логистической регрессии). Этот класс создан специально для логистической регрессии, т.к. для нее известны эффективные алгоритмы перебора параметров.\n",
        "\n",
        "У LogisticRegression есть гиперпараметр C - обратный коэффициент регуляризации. Не вдаваясь в подробное описание по формуле, можно сказать, что C соответствует \"сложности\" модели: чем больше C, тем более сложные зависимости может восстанавливать модель; если параметр C слишком мал (слишком сильная регуляризация), то модель окажется недообученной, а если наоборот регуляризация слишком слабая (т.е. C принимает большие значения), то скорее всего модель окажется переобученной, потому как модель будет слишком \"бояться\" ошибиться на обучающей выборке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1. Используя StratifiedKFold, разбейте данные для кросс-валидации по 5-ти блокам (не забывайте во всех методах использовать random_state=17).\n",
        "2. С помощью numpy.logspace разбейте интервал (-1, 2) на 500 значений.\n",
        "3. С помощью LogisticRegressionCV подберите оптимальный параметр C: установите гиперпараметр Cs равным объекту из п.2 (разбиение интервала (-1, 2) отвечает за подбор обратного коэффициента регуляризации C); cv равным объекту из п.1 (разбиение для кросс-валидации); scoring равным \"roc_auc\" (отвечает за оптимизацию гиперпараметров на кросс-валидации: метрика, установленная в scoring, контролирует, как оценивать модель при каждом из наборе параметров, т.е. показывает, какая метрика должна быть наилучшей).\n",
        "4. Обучите полученную модель на тренировочных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "H-0WuZbphXNy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "0ezY2p2RhXN4"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "cv = StratifiedKFold(random_state=17, shuffle=True, n_splits=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2\n",
        "Cs = np.logspace(-1, 2, 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3\n",
        "lrcv = LogisticRegressionCV(Cs=Cs,cv=cv, scoring='roc_auc', random_state=17)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4\n",
        "lrcv_model = lrcv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6956521739130435"
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lrcv_predict = lrcv.predict(X_test)\n",
        "recall_score(y_test, lrcv_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaE1oixihXN8"
      },
      "source": [
        "### 2.4\n",
        "Используя метод plot из matplotlib.pyplot, выведите график зависимости auc_roc от значения C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRsW0oWQhXN9"
      },
      "source": [
        "*Примечание: значения по оси x - разбиение с помощью np.logspace из п.2 предыдущего задания, а значения по оси y - среднее значение roc_auc по каждой валидации, т.е. среднее значение из полученных на каждом из 5-ти разбиений при данном параметре C (используйте метод scores_ объекта, который инкапсулирует LogisticRegressionCV).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H0CAgq9hXN-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTZtXirYhXOC"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv9qcBE4hXOH"
      },
      "source": [
        "### 2.5\n",
        "С помощью метода C_ того же объекта выведите лучшее значение C. Выведите более конкретную область графика (область ~15 точкам по x), включающую лучшее значение C.\n",
        "\n",
        "*Примечание: используйте plt.xlim.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUoS6KvRhXOI"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ihFwlJhXOL"
      },
      "source": [
        "### 2.6\n",
        "С помощью метода predict_proba получите вероятности принадлежности объектов тестовой выборки к классам. Постройте график roc_auc для тестовой выборки и выведите значение auc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0f_DNEMhXOM"
      },
      "source": [
        "**Пример** построения графика."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzMU7ULahXOM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv5vQq-_hXOR",
        "outputId": "802337a2-3f55-4021-e8d7-0488e63261ba"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'logit_search' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[189], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m probas \u001b[39m=\u001b[39m logit_search\u001b[39m.\u001b[39mfit(x_train, y_train)\u001b[39m.\u001b[39mpredict_proba(x_train)\n\u001b[0;32m      2\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_train, probas[:, \u001b[39m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m auc \u001b[39m=\u001b[39m roc_auc_score(y_train, probas[:, \u001b[39m1\u001b[39m])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'logit_search' is not defined"
          ]
        }
      ],
      "source": [
        "probas = logit_search.fit(x_train, y_train).predict_proba(x_train)\n",
        "fpr, tpr, _ = roc_curve(y_train, probas[:, 1])\n",
        "auc = roc_auc_score(y_train, probas[:, 1])\n",
        "plt.plot(fpr, tpr, label=\"auc=\" + str(auc))\n",
        "plt.legend(loc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ptD2581hXOY"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 ('ds_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "248bc044bc391cd70479aa3aa6b95972b092e756825b5eb21a1dc6ccdc62151a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
